# Copyright 2018 TensorHub, Inc. and contributors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# TODO:
#
# - finetune op
# - detect op
# - auto-scale flag ala slim (auto set clones, etc.)
# - custom image dataset support

# ===================================================================
# Package def
# ===================================================================

- package: gpkg.object-detection
  version: 0.5.0.dev
  description: Object detection library
  url: https://github.com/guildai/packages/tree/master/object-detection
  author: Guild AI
  author-email: packages@guild.ai
  license: Apache 2.0
  requires:
    - gpkg.slim
    - contextlib2
    - lxml
    - matplotlib
    - pillow
    - pycocotools

# ===================================================================
# Shared flag defs
# ===================================================================

- config: train-flags
  flags:
    train-steps:
      description: Number of training steps
      null-label: train indefinitely
    eval-examples:
      description: >
        Number of examples to evaluate after training

        This flag has no effect if `legacy` is `yes`.
      null-label: all available
    legacy:
      description: >
        Use legacy training for object detection

        Multi GPU support is only available with legacy training.

        Unlike default training, legacy training does not perform an
        evaluation after training.
      choices:
        - value: yes
          description: Use legacy training (select for multi GPU support)
        - value: no
          description: Use default training (doesn't support multiple GPUs)
      default: no
      arg-value: yes
    batch-size:
      description: Number of examples in each training batch
    clones:
      description: >
        Number of model clones.

        This flag has no effect unless `legacy` is `yes`.

        Set this value to the number of available GPUs for multi-GPU
        training.
      default: 1

# ===================================================================
# Shared resources
# ===================================================================

- config: models-lib-support
  resources:
    models-lib:
      description: Object detection Python libraries
      private: yes
      sources:
        - url: https://github.com/tensorflow/models/archive/2aec950cf5670a86eb0681e3a0348570c4a4638c.zip
          sha256: cc97bed49476a1984325561dcb29f88a26910689050d9112d02e371209455997
          select:
            - models-2aec950cf5670a86eb0681e3a0348570c4a4638c/research/object_detection
            - models-2aec950cf5670a86eb0681e3a0348570c4a4638c/research/slim/deployment
            - models-2aec950cf5670a86eb0681e3a0348570c4a4638c/research/slim/nets
          post-process: >
            cd models-2aec950cf5670a86eb0681e3a0348570c4a4638c
            && cd research
            && protoc object_detection/protos/*.proto --python_out .

# ===================================================================
# Model base
# ===================================================================

- config: model-base
  extends:
    - models-lib-support
  params:
    pipeline-config-proto: ''
    dataset-config: ''
    model-config: ''
    train-config: ''
    transfer-learn-config: ''
    extra-config: ''
    labels: DEFINE-labels
  operations:

    train:
      description: Train detector from scratch
      main:
        train
          --pipeline-config-proto '{{pipeline-config-proto}}'
          --dataset-config '{{dataset-config}}'
          --model-config '{{model-config}}'
          --train-config '{{train-config}}'
          --extra-config '{{extra-config}}'
      requires:
        - models-lib
        - dataset-config
        - model-config
        - train-config
        - prepared-data
      env:
        PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python
      flags:
        $include: train-flags

    transfer-learn:
      description: Train detector using transfer learning
      main:
        train
          --pipeline-config-proto '{{pipeline-config-proto}}'
          --dataset-config '{{dataset-config}}'
          --model-config '{{model-config}}'
          --train-config '{{transfer-learn-config}}'
          --extra-config '{{extra-config}}'
      requires:
        - models-lib
        - dataset-config
        - model-config
        - transfer-learn-config
        - prepared-data
        - transfer-learn-checkpoint
      env:
        PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python
      flags:
        $include: train-flags

    evaluate:
      description: Evaluate a trained detector
      # Note that 'train-config' is used below because
      # object_detection combines train and eval fn creation in the
      # same function and even through the eval operation doesn't use
      # train config, it needs it here to spoof object_detection to
      # generate the eval fn. In fact any valid train config will work
      # so we use 'train-config'.
      main:
        eval
          --checkpoint-dir checkpoint
          --pipeline-config-proto '{{pipeline-config-proto}}'
          --dataset-config '{{dataset-config}}'
          --model-config '{{model-config}}'
          --train-config '{{train-config}}'
          --extra-config '{{extra-config}}'
      requires:
        - models-lib
        - dataset-config
        - model-config
        - train-config
        - prepared-data
        - trained-model
      env:
        PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python
      flags:
        eval-examples:
          description: Number of examples to evaluate
          null-label: all available

    export-and-freeze:
      description: Export a detection graph with checkpoint weights
      main:
        export_and_freeze
          --checkpoint model
          --dataset-config '{{dataset-config}}'
          --model-config '{{model-config}}'
      requires:
        - models-lib
        - dataset-config
        - model-config
        - trained-model
      env:
        PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python
      flags:
        step:
          description:
            Checkpoint step to use for the frozen graph
          null-label: latest checkpoint

    detect:
      description: Detect images using a trained detector
      main:
        detect
          --images-dir ${images}
          --labels {{labels}}
          --graph frozen_inference_graph.pb
          --output-dir detected
      requires:
        - models-lib
        - frozen-graph
        - labels
      flags:
        images:
          description: Directory containing images to detect
          required: yes

  resources:
    trained-model:
      description: Trained model from train or transfer-learn
      path: model
      sources:
        - operation: train,transfer-learn
          select:
            - train/model\.ckpt.*
            - train/checkpoint
    frozen-graph:
      description: Frozen inference graph from export-and-freeze
      sources:
        - operation: export-and-freeze
          select: graph/frozen_inference_graph\.pb

# ===================================================================
# Faster RCNN base
# ===================================================================

- config: faster-rcnn
  extends:
    - model-base
  params:
    train-config: rcnn-train-default.yml
    transfer-learn-config: rcnn-transfer-learn-default.yml
  resources:
    train-config:
      sources:
        - config/train/rcnn-train-default.yml
    transfer-learn-config:
      sources:
        - config/train/rcnn-transfer-learn-default.yml

# ===================================================================
# Faster RCNN - ResNet
# ===================================================================

- config: faster-rcnn-resnet-50
  extends:
    - faster-rcnn
  params:
    model-config: faster-rcnn-resnet-50.yml
    train-config: rcnn-train-default.yml
  resources:
    transfer-learn-checkpoint:
      path: checkpoint
      sources:
        - url: http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz
          sha256: 0f898f96d6c416de192c516fb6fa773ae9f5ee253eb2ab4015445fbd6eb0ab76
          select:
            - faster_rcnn_resnet50_coco_2018_01_28/model\.ckpt.*
            - faster_rcnn_resnet50_coco_2018_01_28/checkpoint
    model-config:
      sources:
        - config/models/faster-rcnn-resnet-50.yml

- config: faster-rcnn-resnet-101
  extends:
    - faster-rcnn
  params:
    model-config: faster-rcnn-resnet-101.yml
    train-config: rcnn-train-default.yml
  resources:
    transfer-learn-checkpoint:
      path: checkpoint
      sources:
        - url: http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz
          sha256: ef3b36b3bc3c4057362a62e40b89dbdbef3dbb0c91f2f7df43967920d24821e5
          select:
            - faster_rcnn_resnet101_coco_2018_01_28/model\.ckpt.*
            - faster_rcnn_resnet101_coco_2018_01_28/checkpoint
    model-config:
      sources:
        - config/models/faster-rcnn-resnet-101.yml
